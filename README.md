# prompt-eng

This is an experiement in recursive prompt engineering. There has been a lot of discussion recently about the exponentailly increasing value of "prompt engineering" as a skill[1]. I wanted to know: is GTP any good at prompt engineering? If we give it some facts and a target answer, can it generate a question that, when posed back to itself, elicits the correct response? Sort of like Jeopardy for LLMs. TL;DR, yes. Maybe I'll write more about this at soe point.

[1] https://www.forbes.com/sites/craigsmith/2023/04/05/mom-dad-i-want-to-be-a-prompt-engineer/?sh=8b843559c8ef
